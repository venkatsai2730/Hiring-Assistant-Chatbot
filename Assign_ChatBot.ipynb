{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hl0FLQW4ef15",
        "outputId": "7f52725d-f1d0-4ea6-ed20-877ae51a1526"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Authtoken saved to configuration file: /root/.config/ngrok/ngrok.yml\n",
            "Access the app at: NgrokTunnel: \"https://206c-35-223-210-115.ngrok-free.app\" -> \"http://localhost:8501\"\n",
            "\n",
            "Collecting usage statistics. To deactivate, set browser.gatherUsageStats to false.\n",
            "\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m\u001b[1m  You can now view your Streamlit app in your browser.\u001b[0m\n",
            "\u001b[0m\n",
            "\u001b[34m  Local URL: \u001b[0m\u001b[1mhttp://localhost:8501\u001b[0m\n",
            "\u001b[34m  Network URL: \u001b[0m\u001b[1mhttp://172.28.0.12:8501\u001b[0m\n",
            "\u001b[34m  External URL: \u001b[0m\u001b[1mhttp://35.223.210.115:8501\u001b[0m\n",
            "\u001b[0m\n",
            "2025-03-17 06:27:49.761608: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
            "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
            "E0000 00:00:1742192869.780772   16369 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
            "E0000 00:00:1742192869.786186   16369 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
            "Device set to use cpu\n",
            "2025-03-17 06:27:56.791 Examining the path of torch.classes raised:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/web/bootstrap.py\", line 345, in run\n",
            "    if asyncio.get_running_loop().is_running():\n",
            "       ^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: no running event loop\n",
            "\n",
            "During handling of the above exception, another exception occurred:\n",
            "\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 217, in get_module_paths\n",
            "    potential_paths = extract_paths(module)\n",
            "                      ^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/streamlit/watcher/local_sources_watcher.py\", line 210, in <lambda>\n",
            "    lambda m: list(m.__path__._path),\n",
            "                   ^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/torch/_classes.py\", line 13, in __getattr__\n",
            "    proxy = torch._C._get_custom_class_python_wrapper(self.name, attr)\n",
            "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "RuntimeError: Tried to instantiate class '__path__._path', but it does not exist! Ensure that it is registered via torch::class_\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
            "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "Device set to use cpu\n",
            "\u001b[34m  Stopping...\u001b[0m\n",
            "\u001b[34m  Stopping...\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "# Install necessary libraries in Colab\n",
        "!pip install streamlit pyngrok transformers torch -q\n",
        "\n",
        "# Import required libraries\n",
        "import streamlit as st\n",
        "from pyngrok import ngrok\n",
        "from transformers import pipeline\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Write the full Streamlit app code to a file\n",
        "with open(\"app.py\", \"w\") as f:\n",
        "    f.write('''import streamlit as st\n",
        "from transformers import pipeline\n",
        "import time\n",
        "import re\n",
        "\n",
        "# Load pre-trained model for question generation\n",
        "generator = pipeline(\"text-generation\", model=\"gpt2\")  # Using gpt2 for better results\n",
        "\n",
        "# Function to generate technical questions using the LLM\n",
        "def generate_technical_questions(tech_stack):\n",
        "    \"\"\"Generate 3-5 technical questions based on the user's tech stack using the LLM.\"\"\"\n",
        "    prompt = (\n",
        "        f\"Generate a list of 3 to 5 technical interview questions for a candidate proficient in {tech_stack}. \"\n",
        "        \"Focus on practical knowledge and problem-solving skills related to these technologies. \"\n",
        "        \"Format the output as a numbered list (e.g., 1. Question text). Provide only the questions, no extra text.\"\n",
        "    )\n",
        "    response = generator(prompt, max_length=300, num_return_sequences=1, temperature=0.8, top_k=50)[0][\"generated_text\"]\n",
        "\n",
        "    # Extract questions from the response\n",
        "    lines = response.split(\"\\\\n\")\n",
        "    questions = []\n",
        "    for line in lines[1:]:  # Skip the prompt\n",
        "        line = line.strip()\n",
        "        if line and line[0].isdigit() and \".\" in line:  # Check for numbered format (e.g., \"1. \")\n",
        "            questions.append(line)\n",
        "\n",
        "    # Fallback if no questions are generated\n",
        "    if not questions:\n",
        "        questions = [\n",
        "            f\"1. Tell me about a project you built using {tech_stack}.\",\n",
        "            f\"2. What challenges have you faced with {tech_stack} and how did you overcome them?\",\n",
        "            f\"3. Explain a key feature of {tech_stack} that you find most useful.\"\n",
        "        ]\n",
        "\n",
        "    return questions[:5]  # Limit to 5 questions\n",
        "\n",
        "# Validation functions\n",
        "def is_valid_email(email):\n",
        "    \"\"\"Check if the email format is valid.\"\"\"\n",
        "    return re.match(r\"[^@]+@[^@]+\\\\.[^@]+\", email) is not None\n",
        "\n",
        "def is_valid_phone(phone):\n",
        "    \"\"\"Check if the phone number is in a basic valid format (e.g., 123-456-7890 or 1234567890).\"\"\"\n",
        "    return re.match(r\"\\\\d{3}[-.]?\\\\d{3}[-.]?\\\\d{4}\", phone) is not None\n",
        "\n",
        "def is_valid_experience(experience):\n",
        "    \"\"\"Check if experience is a positive number.\"\"\"\n",
        "    try:\n",
        "        return float(experience) >= 0\n",
        "    except ValueError:\n",
        "        return False\n",
        "\n",
        "# Streamlit app logic\n",
        "def main():\n",
        "    # Initialize session state for conversation history and candidate info\n",
        "    if \"messages\" not in st.session_state:\n",
        "        st.session_state.messages = []\n",
        "    if \"candidate_info\" not in st.session_state:\n",
        "        st.session_state.candidate_info = {}\n",
        "    if \"step\" not in st.session_state:\n",
        "        st.session_state.step = \"greeting\"\n",
        "    if \"questions\" not in st.session_state:\n",
        "        st.session_state.questions = []\n",
        "    if \"current_question_index\" not in st.session_state:\n",
        "        st.session_state.current_question_index = 0\n",
        "\n",
        "    # UI Header\n",
        "    st.title(\"TalentScout Hiring Assistant\")\n",
        "    st.write(\"Welcome! I'm here to assist you with your application for tech positions.\")\n",
        "\n",
        "    # Display conversation history\n",
        "    for message in st.session_state.messages:\n",
        "        with st.chat_message(message[\"role\"]):\n",
        "            st.markdown(message[\"content\"])\n",
        "\n",
        "    # Stop further input if conversation has ended\n",
        "    if st.session_state.step == \"end\":\n",
        "        return\n",
        "\n",
        "    # Greeting step\n",
        "    if st.session_state.step == \"greeting\":\n",
        "        greeting = \"Hello! I'm the TalentScout Hiring Assistant. My purpose is to help you apply for tech positions by gathering your information and assessing your skills. Letâ€™s get started! Please provide your full name.\"\n",
        "        st.session_state.messages.append({\"role\": \"assistant\", \"content\": greeting})\n",
        "        st.session_state.step = \"name\"\n",
        "        st.rerun()\n",
        "\n",
        "    # User input\n",
        "    user_input = st.chat_input(\"Type your response here...\")\n",
        "\n",
        "    if user_input:\n",
        "        # Add user message to history\n",
        "        st.session_state.messages.append({\"role\": \"user\", \"content\": user_input})\n",
        "\n",
        "        # Handle conversation flow based on step\n",
        "        with st.chat_message(\"user\"):\n",
        "            st.markdown(user_input)\n",
        "\n",
        "        with st.chat_message(\"assistant\"):\n",
        "            if st.session_state.step == \"name\":\n",
        "                if user_input.strip():\n",
        "                    st.session_state.candidate_info[\"name\"] = user_input.strip()\n",
        "                    response = \"Nice to meet you, {}! Please provide your email address.\".format(user_input)\n",
        "                    st.session_state.step = \"email\"\n",
        "                else:\n",
        "                    response = \"Please provide a valid full name to continue.\"\n",
        "            elif st.session_state.step == \"email\":\n",
        "                if is_valid_email(user_input):\n",
        "                    st.session_state.candidate_info[\"email\"] = user_input\n",
        "                    response = \"Thanks! Now, please provide your phone number (e.g., 123-456-7890).\"\n",
        "                    st.session_state.step = \"phone\"\n",
        "                else:\n",
        "                    response = \"That doesnâ€™t look like a valid email address. Please try again (e.g., example@domain.com).\"\n",
        "            elif st.session_state.step == \"phone\":\n",
        "                if is_valid_phone(user_input):\n",
        "                    st.session_state.candidate_info[\"phone\"] = user_input\n",
        "                    response = \"Great! How many years of experience do you have?\"\n",
        "                    st.session_state.step = \"experience\"\n",
        "                else:\n",
        "                    response = \"Please provide a valid phone number (e.g., 123-456-7890 or 1234567890).\"\n",
        "            elif st.session_state.step == \"experience\":\n",
        "                if is_valid_experience(user_input):\n",
        "                    st.session_state.candidate_info[\"experience\"] = user_input\n",
        "                    response = \"Got it! What position(s) are you applying for?\"\n",
        "                    st.session_state.step = \"position\"\n",
        "                else:\n",
        "                    response = \"Please provide a valid number of years (e.g., 3 or 5.5).\"\n",
        "            elif st.session_state.step == \"position\":\n",
        "                if user_input.strip():\n",
        "                    st.session_state.candidate_info[\"position\"] = user_input.strip()\n",
        "                    response = \"Thanks! Where are you currently located?\"\n",
        "                    st.session_state.step = \"location\"\n",
        "                else:\n",
        "                    response = \"Please specify at least one position youâ€™re applying for.\"\n",
        "            elif st.session_state.step == \"location\":\n",
        "                if user_input.strip():\n",
        "                    st.session_state.candidate_info[\"location\"] = user_input.strip()\n",
        "                    response = \"Perfect! Please tell me about your tech stack (e.g., programming languages, frameworks, tools).\"\n",
        "                    st.session_state.step = \"tech_stack\"\n",
        "                else:\n",
        "                    response = \"Please provide your current location.\"\n",
        "            elif st.session_state.step == \"tech_stack\":\n",
        "                if user_input.strip():\n",
        "                    st.session_state.candidate_info[\"tech_stack\"] = user_input.strip()\n",
        "                    st.session_state.questions = generate_technical_questions(user_input)\n",
        "                    st.session_state.current_question_index = 0\n",
        "                    response = f\"Hereâ€™s your first technical question:\\\\n{st.session_state.questions[0]}\\\\nPlease provide your answer.\"\n",
        "                    st.session_state.step = \"questions\"\n",
        "                else:\n",
        "                    response = \"Please specify your tech stack (e.g., Python, Flask).\"\n",
        "            elif st.session_state.step == \"questions\":\n",
        "                if \"goodbye\" in user_input.lower() or \"exit\" in user_input.lower():\n",
        "                    response = \"Thank you for chatting with me, {}! A recruiter will review your information and get back to you soon. Goodbye!\".format(st.session_state.candidate_info[\"name\"])\n",
        "                    st.session_state.step = \"end\"\n",
        "                else:\n",
        "                    # Check if the answer is meaningful\n",
        "                    if len(user_input.strip()) < 5 or user_input.lower() in [\"idk\", \"i donâ€™t know\", \"skip\"]:\n",
        "                        response = f\"I didnâ€™t quite get that. Could you provide more detail for this question?\\\\n{st.session_state.questions[st.session_state.current_question_index]}\\\\nPlease try again.\"\n",
        "                    else:\n",
        "                        # Move to the next question if available\n",
        "                        st.session_state.current_question_index += 1\n",
        "                        if st.session_state.current_question_index < len(st.session_state.questions):\n",
        "                            response = f\"Thanks for your answer! Hereâ€™s the next question:\\\\n{st.session_state.questions[st.session_state.current_question_index]}\\\\nPlease provide your answer.\"\n",
        "                        else:\n",
        "                            response = \"Thanks for answering all the questions! You can say 'goodbye' or 'exit' to end the conversation, or ask me anything else.\"\n",
        "            else:\n",
        "                response = \"I'm here to assist you with your application. How can I help you next?\"\n",
        "\n",
        "            # Add assistant response to history\n",
        "            st.session_state.messages.append({\"role\": \"assistant\", \"content\": response})\n",
        "            st.markdown(response)\n",
        "\n",
        "            # Rerun to reflect the \"end\" state immediately\n",
        "            if st.session_state.step == \"end\":\n",
        "                st.rerun()\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()\n",
        "''')\n",
        "\n",
        "# Set up ngrok and run Streamlit\n",
        "!ngrok authtoken 2uF5zuwLTgYkh567oQ1hAmUyx1U_7kboSYmKYQg6JAhAXvxFz  # Your provided ngrok auth token\n",
        "public_url = ngrok.connect(8501)\n",
        "print(f\"Access the app at: {public_url}\")\n",
        "\n",
        "# Run Streamlit app\n",
        "!streamlit run app.py --server.port 8501"
      ]
    }
  ]
}